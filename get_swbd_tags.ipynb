{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from spacy.lang.en import English # updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_conv = []\n",
    "taggs = []\n",
    "tagged = [\"tc_processed/train_full_anno.json\", \"tc_processed/test_freq_full_anno.json\", \n",
    "          \"tc_processed/test_rare_full_anno.json\", \"tc_processed/valid_freq_full_anno.json\", \n",
    "          \"tc_processed/valid_rare_full_anno.json\"]\n",
    "for each in tagged:\n",
    "    with open(each) as f:\n",
    "        data = json.load(f)\n",
    "    keys = list(data.keys())\n",
    "    for each in keys:\n",
    "        content = data[each]['content']\n",
    "        c, t = get_conversation(content)\n",
    "        tagged_conv.append(c)\n",
    "        taggs.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "non = \"processed_output/train.src\"\n",
    "with open(non) as f:\n",
    "    src = f.readlines()\n",
    "non_tgt = \"processed_output/train.tgt\"\n",
    "with open(non_tgt) as f:\n",
    "    tgt = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = []\n",
    "for i in range(len(src)-1):\n",
    "    if src[i].replace(\"\\n\", \"\") not in src[i+1]:\n",
    "        original.append(src[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(src)):\n",
    "    text = src[i]\n",
    "    text = text.replace(\"_eos\", \"\")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\" \", \"\")\n",
    "    text = re.sub('\\W+', '', text)\n",
    "    src[i] = text\n",
    "conversations = []\n",
    "for i in range(len(src)-1):\n",
    "    if src[i] not in src[i+1]:\n",
    "        ending = tgt[i].replace(\"\\n\", \"\")\n",
    "        ending = ending.replace(\" \", \"\")\n",
    "        ending = ending.replace(\"_eos\", \"\")\n",
    "        ending = ending.replace(\"_go\", \"\")\n",
    "        ending = re.sub('\\W+', '', ending)\n",
    "        c = src[i] + ending\n",
    "        conversations.append(c)\n",
    "ending = tgt[len(src)-1].replace(\"\\n\", \"\")\n",
    "ending = ending.replace(\" \", \"\")\n",
    "ending = ending.replace(\"_eos\", \"\")\n",
    "ending = ending.replace(\"_go\", \"\")\n",
    "ending = re.sub('\\W+', '', ending)\n",
    "c = src[len(src)-1] + ending\n",
    "conversations.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_convs = []\n",
    "for each in not_in:\n",
    "    current_idx = src.index(original[each])\n",
    "    previous = src[current_idx - 1].replace(\"\\n\", \"\")\n",
    "    current = src[current_idx].replace(\"\\n\", \"\")\n",
    "    c = [current]\n",
    "    while previous in current:\n",
    "        c.insert(0, previous)\n",
    "        current_idx -= 1\n",
    "        current = previous\n",
    "        previous = src[current_idx - 1].replace(\"\\n\", \"\")\n",
    "    not_in_convs.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes i like very much _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos do you know demetri martin wrote a 224 word palindrome poem . _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos do you know demetri martin wrote a 224 word palindrome poem . _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos do you know demetri martin wrote a 224 word palindrome poem . _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos yes i am also think that one _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos do you know demetri martin wrote a 224 word palindrome poem . _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos yes i am also think that one _eos no do you _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos do you know demetri martin wrote a 224 word palindrome poem . _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos yes i am also think that one _eos no do you _eos my guess would be ten million dollars . _eos',\n",
       " 'yes i like very much _eos the earliest western asian epic poetry , the epic of gilgamesh , was written in sumerian _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos how much do you think the original manuscript would be worth now ? _eos sorry i do n\\'t know _eos do you know demetri martin wrote a 224 word palindrome poem . _eos edgar allan poe only received $ 9 for the publication of his poem , \" the raven . \" _eos yes i am also think that one _eos no do you _eos my guess would be ten million dollars . _eos do you know mcdonalds \\' added drive - thru in 1975 to accommodate soldiers who were not allowed to get out of their cars while wearing their fatigues . _eos']"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_in_convs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "11\n",
      "20\n",
      "20\n",
      "21\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for each in not_in_convs:\n",
    "    print(len(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi , how are you ? _eos\n",
      "yes i like very much _eos\n",
      "do you follow elections closely _eos\n",
      "the green bay packers are my favorite football team . i was bummed over the loss to the redskins though ! _eos\n",
      "hello , do you pay much attention to what 's going on in the media ? _eos\n",
      "are you a voter ? _eos\n"
     ]
    }
   ],
   "source": [
    "for each in not_in_convs:\n",
    "    print(each[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43219"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.index(original[2066])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2066, 3475, 4656, 5664, 6348, 7898]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(content):\n",
    "    messages = []\n",
    "    tags = []\n",
    "    for turn in content:\n",
    "        messages.append(turn['message'])\n",
    "        tags.append(turn['mezza_da'])\n",
    "    messages = \"\".join(messages)\n",
    "    messages = messages.replace(\" \", \"\").lower()\n",
    "    messages = messages.replace(\"\\n\", \"\")\n",
    "    messages = messages.replace(\"\\t\", \"\")\n",
    "    messages = re.sub('\\W+','', messages)\n",
    "    return \"\".join(messages), tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for i in range(len(conversations)):\n",
    "    if conversations[i] in tagged_conv:\n",
    "        ids.append(tagged_conv.index(conversations[i]))\n",
    "    else:\n",
    "        ids.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "na_count = 0\n",
    "untagged_len = []\n",
    "tagged_len = []\n",
    "for conv in ids:\n",
    "    if conv != \"NA\":\n",
    "        untagged_len.append(len(taggs[conv])-1)\n",
    "        conv_tag = taggs[conv]\n",
    "        for i in range(1, len(conv_tag)):\n",
    "            output.append(get_taggs(conv_tag[:i]))\n",
    "    else:\n",
    "        untagged_len.append(len(not_in_convs[na_count]))\n",
    "        output = output + not_in_convs[na_count]\n",
    "        na_count +=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_output/train.src.da', 'w') as filehandle:\n",
    "    filehandle.writelines(\"%s\\n\" % place for place in output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179709"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(output)):\n",
    "    docs = nlp(output[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_each_conv = []\n",
    "count = 1\n",
    "for i in range(len(src)-1):\n",
    "    if src[i].replace(\"\\n\", \"\") not in src[i+1]:\n",
    "        length_of_each_conv.append(count)\n",
    "        count = 1\n",
    "    else:\n",
    "        count += 1\n",
    "length_of_each_conv.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179709"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(length_of_each_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taggs(tag_list):\n",
    "    output = \"\"\n",
    "    for i in range(len(tag_list)):\n",
    "        for each in tag_list[i]:\n",
    "            output += f\"{each['da']} \"\n",
    "        if i != len(tag_list) - 1:\n",
    "            output += \"_eos \"\n",
    "    return output[:-1]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2066, 3475, 4656, 5664, 6348, 7898]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925 hihowareyoufineijustreturnedfromatripitraveledtoeuropeiseemslikeairtravelisslowerthesedaysthatitusedtobeamirightyeahsomanysecuritychecksitsreallyirritatingiwouldlovefasterplansthatcouldgoover1000mphorahighspeedrailserviceintheusforintercitytravelthedutcharedesigningaspeedybusforcommuterswhycantwerightyeahourbussystmsaresoslowthedriversroutinelyreleaserabbitsatthebusstopsothatfuturepassengershavesomethingtoeatwhiletheyarewaitingforthenextbuskindoflikeshipsusedtodoleavingrabbitsonislandsilikethatthoughtfulofthedriversbutprobablyincreasesbusfaresifkingkalakauaofhawaiihadtravelledtheworldonbushewouldhavediedbeforecompletingthejourneyyeahhecouldhavewalkedfasterkindofliketheairlineswhoinsteadoffetchingbaggagefasterjustmakeuswalkfurtheriheardtheydidthatinhoustonallthatcomplaintsaboutwaitingforbagsheywhydontyoutakealongwalkaroundtheairportbeforeyougetyourbagsthenthepassengersdidntgetavoteinthatdecisionallthosepoorpeoplecarryingaroundtheirstolengardengnomesatleastitincreasestimefortakingselfiesselfiesattheairportaresohotrightnowinstagramandsnapchatcantkeepupwiththefloodofthemithinktheressomethingfishyaboutalabamaandvoterswhatsupwithblackmenlosingtherighttovotethereidontknowanythingaboutthatastronautsvotefromspacenicefunnythatchimpanzeesbeatusintospaceandin1988achimpgot400000votesinamayoralelectioninriodejaneirounfotunatelyhelostthebestpoliticianinyearstooarealshamechimpanzeesarenaturalpoliticianshistoricallythetallestcandidatehaswonpresidentialelections75ofthetimeiguessgrowthhormonecouldcomeinhandyespeciallyforchimpsjfkwastallerthantrickydickyandhewonhevotedagainstthe1957civilrightsactbuthestillwonjfkalsohadatonofcashsothatprobablyhelpedthewholesystemseemsriggedpeoplehavelosttherighttovotepeopledonthavemoneytorunforofficemaybenbaplayershavetheheightandthecashtomakeagoofpoliticstheycertainlycoulddosomedamageonthesupremecourtithinktheywouldgettonsofvotesmaybenotthe995landslidetheyhadinnorwaybuttheywoulddowelldoyouhearaboutthatnoididntalmost100crazyiwonderhowtallthatpersonwasitwasavoteforindependencesoitwasabigstepintheirhistoryiguesstheywantedtobecomeindependentfromdenmarkdenmarkisaprettyshortcountrysoiguessthatswhytheylostintheuknotallmenhadthevoteuntil1918iwonderwhatdeterminedwhogotthevotefishandchipseitherthatortheyplayedabasketballgameforitalthoughmostbasketballplayergobankruptwhentheyfinishplayingsoiwouldtakethefishandchipswellienjoyedchattingwithyoudontforgettovoteevenifyoureinspaceyoutoobuddyandlikethatgreatcoachstanvangundyoncesaidribashouldntbeplayinggamesonchristmasdaychow\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tagged_conv)):\n",
    "    if '1988' in tagged_conv[i] and '75' in tagged_conv[i]:\n",
    "        if '400000' in tagged_conv[i]:\n",
    "            print(i, tagged_conv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
